{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0f3e6003ee6a07f32fe3e9f6650c86371b095436bfe133f88e169df209bf8a445",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "f3e6003ee6a07f32fe3e9f6650c86371b095436bfe133f88e169df209bf8a445"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Step 4\n",
    "Do the same as Step 3 when instead a context-generation approach is adopted to identify the classes of customers and adopt a potentially different pricing strategy per class. In doing that, evaluate the performance of the pricing strategies in the different classes only at the optimal solution (e.g., if prices that are not optimal for two customers’ classes provide different performance, you do not split the contexts). Let us remark that no discrimination of the customers’ classes is performed at the advertising level. From this Step on, choose one approach between the upper-confidence bound one and the Thompson-sampling one."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Abstract-Super class of Learner\n",
    "class Learner():\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.price = np.linspace(3.0, 15.0, self.n_arms) \n",
    "        self.t = 0  #Time \n",
    "        self.rewards_per_arm = x = [[] for i in range(n_arms)]\n",
    "        self.collected_rewards = []\n",
    "    \n",
    "    def update_observations(self, pulled_arm, reward):\n",
    "        self.rewards_per_arm[pulled_arm].append(reward)\n",
    "        self.collected_rewards.append(reward)\n",
    "\n",
    "##################################   LEARNERS    ##################################\n",
    "# Thompson-Sampling Learner\n",
    "\n",
    "class TS_Learner(Learner):\n",
    "    def __init__(self, n_arms):\n",
    "        super().__init__(n_arms)\n",
    "        #Mean and Std\n",
    "        self.normal_parameters = np.zeros((self.n_arms, 2))\n",
    "\n",
    "    def pull_arm(self):\n",
    "        if self.t < self.n_arms: return self.t\n",
    "        return np.argmax(np.random.normal(self.normal_parameters[: , 0], self.normal_parameters[:, 1]))\n",
    "\n",
    "    def update(self, pulled_arm, reward):\n",
    "        self.t += 1\n",
    "        times_pulled = max(1, len(self.rewards_per_arm[pulled_arm]))\n",
    "        self.update_observations(pulled_arm, reward)\n",
    "        #Empirical mean\n",
    "        self.normal_parameters[pulled_arm, 0] = (self.normal_parameters[pulled_arm, 0] * (times_pulled - 1) + reward ) / times_pulled\n",
    "        #Empirical std\n",
    "        self.normal_parameters[pulled_arm, 1] = np.sqrt(sum((self.normal_parameters[pulled_arm, 0] - self.rewards_per_arm[pulled_arm])**2)/times_pulled)\n",
    "\n",
    "# Upper-Confidence Bound Learner\n",
    "class UCB1(Learner):\n",
    "    def __init__(self, n_arms):\n",
    "        super().__init__(n_arms)\n",
    "        self.empirical_means = np.zeros(n_arms)\n",
    "        self.confidence = np.zeros(n_arms)\n",
    "\n",
    "    def pull_arm(self):\n",
    "        if self.t < self.n_arms:\n",
    "            return self.t \n",
    "        upper_bound = self.empirical_means + self.confidence\n",
    "        return np.random.choice(np.where(upper_bound == upper_bound.max())[0])\n",
    "    \n",
    "    def update(self, pulled_arm, reward):\n",
    "        self.t += 1\n",
    "        self.rewards_per_arm[pulled_arm].append(reward)\n",
    "        self.collected_rewards.append(reward)\n",
    "        self.empirical_means[pulled_arm] = (self.empirical_means[pulled_arm] * (self.t-1) + reward)/self.t\n",
    "        for a in range(self.n_arms):\n",
    "            number_pulled = max(1, len(self.rewards_per_arm[a]) ) \n",
    "            self.confidence[a] = (2*np.log(self.t) /number_pulled)**0.5"
   ]
  },
  {
   "source": [
    "### Main for the experiment\n",
    "\n",
    "Here data is NOT aggregated"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Environment\n",
    "\n",
    "env = Environment()\n",
    "n_arms = 13\n",
    "ucb1_learner_c0 = UCB1(n_arms = n_arms)\n",
    "ucb1_learner_c1 = UCB1(n_arms = n_arms)\n",
    "ucb1_learner_c2 = UCB1(n_arms = n_arms)\n",
    "ts_learner_c0 = TS_Learner(n_arms = n_arms)\n",
    "ts_learner_c1 = TS_Learner(n_arms = n_arms)\n",
    "ts_learner_c2 = TS_Learner(n_arms = n_arms)\n",
    "\n",
    "T = 365\n",
    "opt_bids = [3.9416202240277745 , 3.0,  4.0]\n",
    "opt_price = 7\n",
    "regret_c0_ucb = []\n",
    "regret_c1_ucb = []\n",
    "regret_c2_ucb = []\n",
    "\n",
    "regret_c0_ts = []\n",
    "regret_c1_ts = []\n",
    "regret_c2_ts = []\n",
    "\n",
    "# Use this for testing, the price learned is 7, the optimal one\n",
    "# bids = opt_bids \n",
    "bids = [5.0, 5.0, 5.0]\n",
    "prices = np.linspace(3.0, 15.0, n_arms)\n",
    "\n",
    "price_ev_per_day_ucb = []\n",
    "price_ev_per_day_ts = []\n",
    "\n",
    "for day in range(T):\n",
    "    #UCB1 learner\n",
    "    price_c0_idx = ucb1_learner_c0.pull_arm()\n",
    "    price_c0 = prices[price_c0_idx]\n",
    "    price_c1_idx = ucb1_learner_c1.pull_arm()\n",
    "    price_c1 = prices[price_c1_idx]\n",
    "    price_c2_idx = ucb1_learner_c2.pull_arm()\n",
    "    price_c2 = prices[price_c2_idx]\n",
    "    \n",
    "    reward_per_day = []\n",
    "    price = [price_c0, price_c1, price_c2]\n",
    "    for i in range(len(price)):\n",
    "        p = price[i]\n",
    "        reward = env.round(bids, p)\n",
    "        reward_per_day.append(reward[i]) \n",
    "\n",
    "    ucb1_learner_c0.update(price_c0_idx, reward_per_day[0])\n",
    "    ucb1_learner_c1.update(price_c1_idx, reward_per_day[1])\n",
    "    ucb1_learner_c2.update(price_c2_idx, reward_per_day[2])\n",
    "    \n",
    "    reward_optimal = env.round(opt_bids, opt_price, noise= False)\n",
    "    regret_c0 = reward_optimal[0] - reward_per_day[0]\n",
    "    regret_c1 = reward_optimal[1] - reward_per_day[1]\n",
    "    regret_c2 = reward_optimal[2] - reward_per_day[2]\n",
    "    regret_c0_ucb.append(regret_c0)\n",
    "    regret_c1_ucb.append(regret_c1)\n",
    "    regret_c2_ucb.append(regret_c2)\n",
    "\n",
    "    price_ev_per_day_ucb.append(price)\n",
    "\n",
    "    #TS learner\n",
    "    price_c0_idx = ts_learner_c0.pull_arm()\n",
    "    price_c0 = prices[price_c0_idx]\n",
    "    price_c1_idx = ts_learner_c1.pull_arm()\n",
    "    price_c1 = prices[price_c1_idx]\n",
    "    price_c2_idx = ts_learner_c2.pull_arm()\n",
    "    price_c2 = prices[price_c2_idx]\n",
    "    \n",
    "    reward_per_day = []\n",
    "    price = [price_c0, price_c1, price_c2]\n",
    "    for i in range(len(price)):\n",
    "        p = price[i]\n",
    "        reward = env.round(bids, p)\n",
    "        reward_per_day.append(reward[i]) \n",
    "\n",
    "    ts_learner_c0.update(price_c0_idx, reward_per_day[0])\n",
    "    ts_learner_c1.update(price_c1_idx, reward_per_day[1])\n",
    "    ts_learner_c2.update(price_c2_idx, reward_per_day[2])\n",
    "    \n",
    "    reward_optimal = env.round(opt_bids, opt_price, noise= False)\n",
    "    regret_c0 = reward_optimal[0] - reward_per_day[0]\n",
    "    regret_c1 = reward_optimal[1] - reward_per_day[1]\n",
    "    regret_c2 = reward_optimal[2] - reward_per_day[2]\n",
    "    regret_c0_ts.append(regret_c0)\n",
    "    regret_c1_ts.append(regret_c1)\n",
    "    regret_c2_ts.append(regret_c2)\n",
    "\n",
    "    price_ev_per_day_ts.append(price)\n"
   ]
  },
  {
   "source": [
    "## Plots"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(0)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(regret_c0_ucb,'r', label=\"UCB-c0\")\n",
    "plt.plot(regret_c1_ucb, 'b', label=\"UCB-c1\")\n",
    "plt.plot(regret_c2_ucb, 'g', label=\"UCB-c2\")\n",
    "plt.title(\"Step 4 - UCB1 regret\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(1)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(regret_c0_ts,'r', label=\"TS-c0\")\n",
    "plt.plot(regret_c1_ts, 'b', label=\"TS-c1\")\n",
    "plt.plot(regret_c2_ts, 'g', label=\"TS-c2\")\n",
    "plt.title(\"Step 4 - TS regret\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Regret: UCB vs TS per class')\n",
    "axs[0].plot(regret_c0_ucb,'y', label=\"UCB-c0\", linestyle=\"dashed\")\n",
    "axs[0].plot(regret_c0_ts,'r', label=\"TS-c0\")\n",
    "axs[0].legend()\n",
    "axs[1].plot(regret_c1_ucb,'y', label=\"UCB-c1\", linestyle=\"dashed\")\n",
    "axs[1].plot(regret_c1_ts,'b', label=\"TS-c1\")\n",
    "axs[1].legend()\n",
    "axs[2].plot(regret_c2_ucb,'y', label=\"UCB-c2\", linestyle=\"dashed\")\n",
    "axs[2].plot(regret_c2_ts,'g', label=\"TS-c2\")\n",
    "axs[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "YY_ucb = np.array(price_ev_per_day_ucb) \n",
    "YY_ts = np.array(price_ev_per_day_ts)\n",
    "\n",
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Estimated price: UCB vs TS per class')\n",
    "axs[0].plot(YY_ucb[:,0],'y', linestyle=\"dashed\")\n",
    "axs[0].plot(YY_ts[:,0],'r')\n",
    "axs[0].hlines(opt_price, 0, 365, 'g', linestyles='dashed')\n",
    "axs[0].set(ylabel=\"Class 0\")\n",
    "axs[1].plot(YY_ucb[:,1],'y', linestyle=\"dashed\")\n",
    "axs[1].plot(YY_ts[:,1],'r')\n",
    "axs[1].hlines(opt_price, 0, 365, 'g', linestyles='dashed')\n",
    "axs[1].set(ylabel=\"Class 1\")\n",
    "axs[2].plot(YY_ucb[:,2],'y', linestyle=\"dashed\")\n",
    "axs[2].plot(YY_ts[:,2],'r')\n",
    "axs[2].hlines(opt_price, 0, 365, 'g', linestyles='dashed')\n",
    "axs[2].set(ylabel=\"Class 2\")\n",
    "fig.legend([\"UCB\",\"TS\",\"Optimal Price\"])"
   ]
  }
 ]
}